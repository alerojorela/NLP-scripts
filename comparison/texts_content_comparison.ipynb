{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a928ed2",
   "metadata": {},
   "source": [
    "# Textual similarity\n",
    "This script does not take into account semantic similarity, for instance, it would recognize as differents:\n",
    "over ~ above\n",
    "+ using [Pyvis](https://pyvis.readthedocs.io/en/latest/index.html) library (built around the VisJS library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8ee55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in /home/targa/anaconda3/lib/python3.9/site-packages (0.3.2)\n",
      "Requirement already satisfied: networkx>=1.11 in /home/targa/anaconda3/lib/python3.9/site-packages (from pyvis) (2.7.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /home/targa/anaconda3/lib/python3.9/site-packages (from pyvis) (8.2.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /home/targa/anaconda3/lib/python3.9/site-packages (from pyvis) (3.0.1)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /home/targa/anaconda3/lib/python3.9/site-packages (from pyvis) (2.11.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (3.0.20)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (2.11.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.1.2)\n",
      "Requirement already satisfied: backcall in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (61.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in /home/targa/anaconda3/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/targa/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/targa/anaconda3/lib/python3.9/site-packages (from jinja2>=2.9.6->pyvis) (2.0.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/targa/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/targa/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.5)\n",
      "Requirement already satisfied: asttokens in /home/targa/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/targa/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/targa/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: six in /home/targa/anaconda3/lib/python3.9/site-packages (from asttokens->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313611e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.metrics.distance import *\n",
    "\n",
    "from pyvis.network import Network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d770f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [\"\"\"\n",
    "The Way that can be told of is not the eternal Way;\n",
    "The name that can be named is not the eternal name.\n",
    "The Nameless is the origin of Heaven and Earth;\n",
    "The Named is the mother of all things.\n",
    "\n",
    "Therefore let there always be non-being,\n",
    "  so we may see their subtlety,\n",
    "And let there always be being,\n",
    "  so we may see their outcome.\n",
    "The two are the same,\n",
    "But after they are produced,\n",
    "  they have different names.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "The Nameless is the origin of Heaven and Earth;\n",
    "The named is the mother of all things.\n",
    "\n",
    "Therefore let there always be non-being,\n",
    "  so we may see their subtlety,\n",
    "And let there always be being,\n",
    "  so we may see their outcome.\n",
    "The two are the same,\n",
    "But after they are produced,\n",
    "  they have different names.\n",
    "\n",
    "They both may be called deep and profound.\n",
    "Deeper and more profound,\n",
    "The door of all subtleties!\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e41bc6",
   "metadata": {},
   "source": [
    "## Similarity metrics\n",
    "+ semantic (based on word embeddings): cosine similarity, euclidean distance\n",
    "+ literal: Jaccard distance, word mover’s distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61323f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# , sklearn.metrics.jaccard_score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9274d421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 tokens_jaccard_similarity\n",
      "0.8134680134680135 jaro_similarity\n",
      "0.888080808080808 jaro_winkler_similarity\n",
      "4 edit_distance\n"
     ]
    }
   ],
   "source": [
    "def tokens_jaccard_similarity(a, b):\n",
    "    # convert to set\n",
    "    a = set(a.split())\n",
    "    b = set(b.split())\n",
    "    # calucate jaccard similarity\n",
    "    return float(len(a.intersection(b))) / len(a.union(b))\n",
    "\n",
    "# SAMPLE OUTPUTS\n",
    "\"\"\"\n",
    "Calculate the minimum Levenshtein edit-distance based alignment mapping between two strings. The alignment finds the mapping from string s1 to s2 that minimizes the edit distance cost. For example, mapping “rain” to “shine” would involve 2 substitutions, 2 matches and an insertion resulting in the following mapping: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (4, 5)] NB: (0, 0)\n",
    "jaccard_similarity  # Distance metric comparing set-similarity\n",
    "jaro_similarity\n",
    "jaro_winkler_similarity  # extension of the Jaro similarity (William E. Winkler. 1990)\n",
    "\"\"\"\n",
    "functions = (tokens_jaccard_similarity, jaro_similarity, jaro_winkler_similarity, edit_distance)\n",
    "for func in functions:\n",
    "    print(func( 'The two are the same', 'The three are the same'), func.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893118bf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf574e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test1 test2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(text):\n",
    "    # equivalent\n",
    "    return re.sub('[ \\t]{2,}', ' ', text).strip()\n",
    "\n",
    "d = \"    test1 \t\ttest2  \"\n",
    "normalize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "454b7fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The Way that can be told of is not the eternal Way;',\n",
       "  'The name that can be named is not the eternal name.',\n",
       "  'The Nameless is the origin of Heaven and Earth;',\n",
       "  'The Named is the mother of all things.',\n",
       "  'Therefore let there always be non-being,',\n",
       "  'so we may see their subtlety,',\n",
       "  'And let there always be being,',\n",
       "  'so we may see their outcome.',\n",
       "  'The two are the same,',\n",
       "  'But after they are produced,',\n",
       "  'they have different names.'],\n",
       " ['The Nameless is the origin of Heaven and Earth;',\n",
       "  'The named is the mother of all things.',\n",
       "  'Therefore let there always be non-being,',\n",
       "  'so we may see their subtlety,',\n",
       "  'And let there always be being,',\n",
       "  'so we may see their outcome.',\n",
       "  'The two are the same,',\n",
       "  'But after they are produced,',\n",
       "  'they have different names.',\n",
       "  'They both may be called deep and profound.',\n",
       "  'Deeper and more profound,',\n",
       "  'The door of all subtleties!']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into lines\n",
    "texts = []\n",
    "for text in raw_texts:\n",
    "    t1 = re.split('\\n', text)\n",
    "    t1 = [normalize(_) for _ in t1 if _]\n",
    "    texts.append(t1)\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a93b2",
   "metadata": {},
   "source": [
    "## Matrices <-> Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc22f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_length = 20\n",
    "def create_graph(matrix, texts, threshold=0):\n",
    "    A_nodes, B_nodes = matrix.shape[0], matrix.shape[1]\n",
    "    print(f'nodes: {A_nodes} from A, {B_nodes} from A , {A_nodes + B_nodes} total')\n",
    "    \n",
    "    nx_graph = nx.Graph()\n",
    "    # nodes\n",
    "    # matrix\n",
    "    for i in range(A_nodes):\n",
    "        global_i = i\n",
    "        text = texts[0][i]\n",
    "        nx_graph.add_node(global_i, size=20, group=1,\n",
    "                          label=text[:label_length]+'...', title=text)\n",
    "    for j in range(B_nodes):\n",
    "        global_j = j + A_nodes  # avoid overlapping nodes. it's not an adjacency matrix\n",
    "        text = texts[1][j]\n",
    "        nx_graph.add_node(global_j, size=20, group=2,\n",
    "                          label=text[:label_length]+'...', title=text)\n",
    "    \n",
    "    # text chain: chains items into a sequence graph\n",
    "    for i in range(1, A_nodes):\n",
    "        global_i = i\n",
    "        nx_graph.add_edge(global_i-1, global_i, weight=1)\n",
    "        \n",
    "    for j in range(1, B_nodes):\n",
    "        global_j = j + A_nodes  # avoid overlapping nodes. it's not an adjacency matrix\n",
    "        nx_graph.add_edge(global_j-1, global_j, weight=1)\n",
    "    \n",
    "    nodes_indices = list(nx_graph.nodes)\n",
    "    print('nodes indices: ', nodes_indices)\n",
    "    print('nodes from A: ', nodes_indices[:A_nodes])\n",
    "    print('nodes from B: ', nodes_indices[A_nodes:])\n",
    "    \n",
    "    # START NODE\n",
    "    start_node_index = A_nodes + B_nodes\n",
    "    nx_graph.add_node(start_node_index, size=25, group=0, label='START')\n",
    "    nx_graph.add_edge(start_node_index, 0)\n",
    "    nx_graph.add_edge(start_node_index, A_nodes)\n",
    "    # nx_graph.add_edge(0, start_node_index)\n",
    "    # nx_graph.add_edge(A_nodes, start_node_index)\n",
    "    \n",
    "    # edges\n",
    "    for i in range(A_nodes):\n",
    "        for j in range(B_nodes):\n",
    "            if matrix[i,j]:\n",
    "                global_j = j + A_nodes\n",
    "                nx_graph.add_edge(i, global_j, weight=int(5 * matrix[i,j]))\n",
    "                \n",
    "    return nx_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a46822b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def comparison_matrix(texts, comparison_function):\n",
    "    # creates a cartesian product matrix from two texts already divide into units\n",
    "    # e.g. units: lines <- paragraphs,  sentences\n",
    "    # rows from argument index 0, columns from argument index 1\n",
    "    matrix = np.zeros((len(texts[0]), len(texts[1])))\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            pair = texts[0][i], texts[1][j]\n",
    "            metric = comparison_function(*pair)\n",
    "            matrix[i, j] = metric\n",
    "            # print(metric, pair)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3e6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "jaro_similarity\n",
    "# functions = (tokens_jaccard_similarity, jaccard_similarity, jaro_similarity, jaro_winkler_similarity, edit_distance)\n",
    "functions = (tokens_jaccard_similarity, jaro_similarity, jaro_winkler_similarity, edit_distance)\n",
    "\n",
    "comparison_function = tokens_jaccard_similarity  # extension of the Jaro similarity (William E. Winkler. 1990)\n",
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00dd8bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = comparison_matrix(texts, comparison_function=comparison_function)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5d171a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.77777778, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.71428571, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.71428571, 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold\n",
    "# float matrix -> boolean matrix\n",
    "boolean_matrix = (matrix >= threshold).astype(int)\n",
    "# zero all values below threshold\n",
    "matrix[matrix < threshold] = 0\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8936372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0]]\n",
      "\n",
      "COMPARISON between A and B:\n",
      "    - B deletions\n",
      "    + B additions\n",
      "    ? ambiguity (multiple edges pointing to the same node)\n",
      "\n",
      "- The Way that can be told of is not the eternal Way;\n",
      "- The name that can be named is not the eternal name.\n",
      "?: so we may see their subtlety,\n",
      "?: so we may see their outcome.\n",
      "?: so we may see their subtlety,\n",
      "?: so we may see their outcome.\n",
      "+ They both may be called deep and profound.\n",
      "+ Deeper and more profound,\n",
      "+ The door of all subtleties!\n"
     ]
    }
   ],
   "source": [
    "print(boolean_matrix)\n",
    "\n",
    "print(\"\"\"\n",
    "COMPARISON between A and B:\n",
    "    - B deletions\n",
    "    + B additions\n",
    "    ? ambiguity (multiple edges pointing to the same node)\n",
    "\"\"\")\n",
    "\n",
    "# A: present in A, absent in B\n",
    "pa = np.count_nonzero(boolean_matrix, axis=1)\n",
    "for index, count in enumerate(pa):\n",
    "    if count == 0:\n",
    "        print('-', texts[0][index])\n",
    "    elif count > 1:\n",
    "        print('?:', texts[0][index])\n",
    "\n",
    "pa = np.count_nonzero(boolean_matrix, axis=0)\n",
    "for index, count in enumerate(pa):\n",
    "    if count == 0:\n",
    "        print('+', texts[1][index])\n",
    "    elif count > 1:\n",
    "        print('?:', texts[1][index])\n",
    "        \n",
    "# analyze crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f886a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76e20d6",
   "metadata": {},
   "source": [
    "# As a DNA strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4038ae92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 11 from A, 12 from A , 23 total\n",
      "nodes indices:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "nodes from A:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "nodes from B:  [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "nx.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f69660bee50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx_graph = create_graph(matrix, texts)\n",
    "directed=True\n",
    "\n",
    "nt = Network(notebook=True, height=\"750px\", width=\"100%\",\n",
    "             cdn_resources='remote', filter_menu =True,\n",
    "             directed =directed)\n",
    "\n",
    "\n",
    "nt.from_nx(nx_graph)\n",
    "nt.show(\"nx.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fee70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43649493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
